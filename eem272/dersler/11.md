```python
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
```


```python
# 1. Veriyi yükle
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 2. Normalize et ve giriş şekline göre yeniden boyutlandır (28x28x1)
x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype("float32") / 255.0
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype("float32") / 255.0
```


```python
# 3. Etiketleri one-hot encode yap
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
```


```python
# 4. Sequential model oluştur
model = models.Sequential([
    layers.Input(shape=(28, 28, 1)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])
```


```python
# 5. Derleme (compile)
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
```

**`optimizer` (optimizasyon algoritmaları)**

| Optimizer    | Açıklama                                                                      |
| ------------ | ----------------------------------------------------------------------------- |
| `'adam'`     | Genelde iyi sonuçlar verir, adaptif öğrenme oranı sağlar.                     |
| `'sgd'`      | Stokastik Gradient Descent – klasik yöntemdir. Momentum ile geliştirilebilir. |
| `'rmsprop'`  | RNN gibi zaman serisi modellerinde iyi sonuçlar verir.                        |
| `'adagrad'`  | Sık güncellenen parametreler için öğrenme oranını düşürür.                    |
| `'adadelta'` | `adagrad`'a benzer ama sabit öğrenme oranı gerektirmez.                       |
| `'adamax'`   | `adam`’ın sonsuz normla çalışan versiyonudur.                                 |

 
Ayrıntılar için <https://medium.com/@astitwa15108824/comparative-analysis-of-adam-optimizer-and-its-variants-adamax-rmsprop-and-adagrad-addressing-02889adc8735>

| Loss Fonksiyonu                     | Ne Zaman Kullanılır?                                    |
| ----------------------------------- | ------------------------------------------------------- |
| `'categorical_crossentropy'`        | One-hot encoded çok sınıflı sınıflandırma için          |
| `'sparse_categorical_crossentropy'` | Etiketler tamsayı (one-hot değil) ise                   |
| `'binary_crossentropy'`             | İkili sınıflandırma için                                |
| `'mean_squared_error'` (`'mse'`)    | Regresyon problemleri için                              |
| `'mean_absolute_error'` (`'mae'`)   | Regresyon için, hatanın mutlak değeri önemliyse         |


| Metric                                                                | Açıklama                                                                      |
| --------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| `'accuracy'`                                                          | Doğru sınıflandırma oranı (çok sınıflı veya ikili)                            |
| `'sparse_categorical_accuracy'`                                       | Tamsayı etiketlerle `sparse_categorical_crossentropy` ile birlikte kullanılır |
| `'mae'`                                                               | Ortalama mutlak hata (regresyon için)                                         |
| `'mse'`                                                               | Ortalama kare hata                                                            |




```python
# 6. Eğitme
history = model.fit(x_train, y_train,
                    epochs=50,
                    batch_size=64,
                    validation_data=(x_test, y_test))

# alternatif:
# history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)

# 7. Test seti üzerinde değerlendirme
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test doğruluğu: {test_acc:.4f}")
```


```python
# 8. Başarı grafikleri
plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.title("Doğruluk Grafiği")
plt.xlabel("Epoch")
plt.ylabel("Doğruluk")
plt.legend()
plt.show()
```

## Callbacks


```python
from tensorflow.keras.callbacks import EarlyStopping
```


```python
earlystop = EarlyStopping(monitor='val_accuracy',
                             patience=3,       # 3 epoch boyunca iyileşme yoksa durur
                             restore_best_weights=True,
                             verbose=1)
```


```python
callbacks = [earlystop]
```


```python
history = model.fit(x_train, y_train,
                    epochs=50,
                    batch_size=64,
                    validation_data=(x_test, y_test),
                    callbacks=callbacks)
```


```python

```

## Keras Tuner


```python
from tensorflow import keras
from tensorflow.keras import layers
import keras_tuner as kt

def build_model(hp):
    model = keras.Sequential()
    
    # Girdi
    model.add(layers.Input(shape=(28, 28, 1)))

    # Conv2D Katmanı 1
    model.add(layers.Conv2D(
        filters=hp.Choice('conv_1_filters', values=[32, 64, 128]),
        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),
        activation=hp.Choice('conv_activation', values=['relu', 'tanh'])
    ))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Conv2D Katmanı 2
    model.add(layers.Conv2D(
        filters=hp.Choice('conv_2_filters', values=[64, 128, 256]),
        kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),
        activation=hp.Choice('conv_activation', values=['relu', 'tanh'])
    ))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Fully Connected
    model.add(layers.Flatten())
    model.add(layers.Dense(
        units=hp.Choice('dense_units', values=[64, 128, 256]),
        activation=hp.Choice('dense_activation', values=['relu', 'tanh'])
    ))
    model.add(layers.Dense(10, activation='softmax'))

    # Derleyici
    model.compile(
        optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd']),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

```


```python

```


```python

```


```python
from keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

# Veriyi yükle
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize et ve giriş şekline göre yeniden boyutlandır (28x28x1)
x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype("float32") / 255.0
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype("float32") / 255.0

y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Tuner oluştur
tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir',
    project_name='mnist_tuning'
)

# Tuning başlat
tuner.search(
    x_train, y_train,
    epochs=5,
    validation_data=(x_test, y_test),
    callbacks=[keras.callbacks.EarlyStopping(patience=2)])


```
